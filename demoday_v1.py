# -*- coding: utf-8 -*-
"""demoday_candra_v1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JcWC9-FljpFujxBlRpKuNloqqf2NCptW
"""

import tensorflow as tf
from tensorflow import keras

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

df_train = pd.read_csv("train.csv",sep=';')
df_test = pd.read_csv("test.csv",sep=';')
df_train

"""Dataset yang digunakan sebanyak 45211 dimana dataset terdiri atas 16 kolom yang diantaranya terdapat kolom berjenis kategorikal dan numerikal dan 1 kolom berjenis binari
1. Kolom age - usia(numerikal).
2. Kolom job - pekerjaan (kategorikal).
3. Kolom marital - status pernikahan (kategorikal).
4. Kolom education - pendidikan terakhir(kategorikal).
5. Kolom default - status kredit pelanggan (kategorikal).
6. Kolom balance - saldo pelanggan (numerikal).
7. Kolom housing - status pinjaman untuk perumahan (kategorikal).
8. Kolom loan - status pinjaman pribadi (kategorikal).
9. Kolom contact - cara bank menghubungi klien (kategorikal).
10. Kolom day - hari terakhir komunikasi yang dilakukan kepada pelanggan (kategorikal).
11. Kolom month - bulan terakhir komunikasi yang dilakukan kepada pelanggan (kategorikal).
12. Kolom duration - durasi terakhir komunikasi yang dilakukan kepada pelanggan (numerikal).
13. Kolom campaign - jumlah kontak yang dilakukan kepada pelanggan selama masa campaign (numerikal).
14. Kolom pdays - jumlah hari yang berlalu setelah pelanggan dihubungi dari campaign sebelumnya (numerikal).
15. Kolom previous - jumlah panggilan yang dilakukan sebelum campaign sekarang (numerikal).
16. Kolom poutcome - status hasil dari campaign sebelumnya (kategorikal).
17. Kolom y - apakah klien sudah berlangganan deposito berjangka? (binari)
"""

df_train.describe()

"""1. Pada kolom age menunjukkan sebaran data pelanggan berada pada rentang usia 18 hingga 95 tahun dengan rata-rata pelanggan berumur 40 tahun
2. Terdapat saldo pelanggan yang bernilai negatif (kolom negatif), yang artinya pelanggan tersebut telah menggunakan layanan melebihi saldo yang dimiliki
3. Terdapat pelanggan yang telah dikontak oleh pihak campaign sebanyak 63 kali selama masa campaign
4. Nilai -1 pada kolom p-days menunjukkan bahwa pelanggan tersebut belum pernah dikontak oleh tim campaign pada masa campaign sebelumnya atau dengan kata lain pelanggan tersebut adalah pelanggan baru
"""

df_train.describe(include='object')

"""Mayoritas pelanggan berprofesi blue-collar, kebanyakan pelanggan telah menikah, pendidikan terakhir didominasi oleh mereka yang lulus dari secondary school. Kebanyakan pelanggan juga memilki tanggungan pinjaman rumah. Kemudian, layanan yang paling banyak digunakan oleh pelanggan adalah cellular. Bulan mei merupakan penggunaan layanan tertinggi dalam satu tahun

Label didominasi oleh nilai "no" yang artinya lebih banyak pelanggan yang tidak berlangganan deposito berjangka
"""

sns.countplot(data=df_train,x = 'y');plt.show()

"""Cek missing value dan duplicate data"""

print("Missing : ",df_train.isna().sum().sum())
print("Duplikat : ",df_train.duplicated().sum())

"""Cek konsistensi data

Kolom bertipe data objek cenderung memiliki data yang tidak konsisten
"""

df_train.dtypes

"""Kolom bertipe data objek cenderung memiliki data yang tidak konsisten. Umumnya disebabkan oleh kesalahan input"""

for col in df_train.columns:
    if df_train[col].dtype == 'object':
        print(col," : ",list(df_train[col].unique()))

"""Dapat diamati, data yang terekam konsisten. Namun pada beberapa kolom terdapat nilai "unknown" yang kurang mereperesentasikan sesuatu. Nilai "unknown" pada beberapa kolom tersebut akan diatasi pada tahap cleansing data

Cleansing dataset
"""

def convertValue(df):
    # Ubah nilai pada kolom target (y). yes menjadi 1 dan no menjadi nol
    df['y'].replace(to_replace='yes', value=1, inplace=True)
    df['y'].replace(to_replace='no', value=0, inplace=True)

    # Usia dari para nasabah sangat beragam, untuk menyederhanakannya, kami akan mengelompokkan usia nasabah ke dalam empat kelompok, yaitu : 
    # 1. Remaja (11-19 tahun)
    # 2. Dewasa (20-60 tahun)
    # 3. Lansia (61-inf)
    df.loc[((df.age > 10) & (df.age < 20)),  'AgeGroup'] = 'remaja'
    df.loc[((df.age > 19) & (df.age < 61)),  'AgeGroup'] = 'dewasa'
    df.loc[(df.age > 60),  'AgeGroup'] = 'lansia'

    df = df.drop('age', axis=1)

    # Ubah nama bulan ke dalam bentuk numerik
    months = {'jan':1, 'feb':2, 'mar':3, 'apr':4, 'may':5, 'jun':6, 'jul':7, 'aug':8, 'sep':9, 'oct':10, 'nov':11, 'dec': 12}
    df['month'] = df['month'].map(months)

    # Ubah nilai kolom default, housing dan loan ke dalam bentuk numerik
    default = {'yes':1, 'no':0}
    df['default'] = df['default'].map(default)
    df['housing'] = df['housing'].map(default)
    df['loan'] = df['loan'].map(default)

    return df

df_train = convertValue(df_train)

df_test = convertValue(df_test)

"""Type data dari beberapa kolom adalah object, sehingga perlu diubah kedalam bentuk kategorikal"""

def convert_to_categorical(df):
    for col in df.columns:
        if df[col].dtype == object:
            df[col] = df[col].astype("category")
    return df

df_train = convert_to_categorical(df_train)
df_test = convert_to_categorical(df_test)
df_train.dtypes

"""Encode nilai pada setiap kolom kategorikal"""

# df = pd.get_dummies(df_train); #Konversi kolom bertipe objek menjadi one hot encode untuk mencari korelasi
df = df_train.copy()
for col in df.columns:
    if df_train[col].dtype != 'int64':
        df[f'{col}-encode'] = df[col].cat.codes
df

"""Hasil berikut menunjukkan, nilai "unknown" terdapat pada kolom job, education, contact dan poutcome"""

unknown_val = {}
for col in df_train.columns:
    unknown_val[col] = df_train[df_train[col] == 'unknown'][col].count()

pd.DataFrame.from_dict(unknown_val,orient='index',columns=["Count"])

"""Data pada kolom job yang bernilai "unknown" tidak bisa langsung kita asumsikan bahwa seseorang tidak memiliki pekerjaan, karena pada kolom job terdapat nilai "unemployed" dan "retired". Kemungkinan nilai unknown muncul karena proses pencatatan data yang kurang baik.

Dapat dilihat pada kolom job, data bernilai "unknown" berjumlah sebanyak 288 atau sebanyak 0.6% dari keseluruhan data

Teknik yang umum digunakan untuk mengatasi masalah tersebut adalah dengan menggunakan nilai modus pada kolom tersebut, namun hal ini dapat berdampak pada meningkatknya jumlah data pada nilai tertentu sehingga menyebabkan bias. Pada dataset ini, profesi terbanyak adalah blue-collar

Cara lainnya adalah dengan mengamati kolom lainnya. Kolom lainnya yang memiliki korelasi tinggi dapat dimanfaatkan untuk mengganti nilai "unknown" pada kolom job.

Umumnya profesi seseorang berkaitan erat dengan latar belakang pendidikannya. Apakah semakin tinggi pendidikan seseorang maka pekerjaan yang dimiliki seseorang juga semakin baik?
"""

print(df_train[df_train['education']=='primary']['job'].value_counts()[:5])
print()
print(df_train[df_train['education']=='secondary']['job'].value_counts()[:5])
print()
print(df_train[df_train['education']=='tertiary']['job'].value_counts()[:5])
print()

"""Dapat diamati : 
1. Orang dengan status pendidikan "primary" didominasi oleh "blue-collar".
2. Masih ditemukan profesi yang sama dengan sebelumnya (blue-collar) pada status pendidikan "secondary" namun selisih dengan profesi lainnya tidak terlalu signifikan.
3. Pada status pendidikan "tertiary" didominasi oleh "management"

Berdasarkan hasil di atas, asumsi bahwa semakin tinggi pendidikan seseorang maka pekerjaan yang dimiliki seseorang juga semakin baik bisa diterima
"""

# Cek apakah terdapat pelanggan yang status pekerjaannya "unknown" namun pendidikannya "tertiary"?
df_train[(df_train['job']=="unknown") & (df_train['education']=='tertiary')].head()

"""Lalu, bagaimana jika status pendidikannya juga "unknown"?

Kita bisa menggunakan kolom lain yang memiliki korelasi tertinggi lainnya
"""

plt.figure(figsize=(15,8))
df.corr()['job-encode'].sort_values(ascending=False).plot(kind='bar') #Kolom job-encode adalah job yang telah diencode agar bisa dicari korelasinya dengan kolom lain

"""Dari grafik di atas, kolom education dan marital memiliki nilai korelasi yang cukup tinggi terhadap kolom job

Dengan demikian, Kolom berikutnya yang akan digunakan adalah kolom marital/status pernikahan. Kolom tersebut terdiri atas 3 nilai yaitu married, single dan divorce
Sebagai contoh, kita akan mencari profesi dari pelanggan dengan status pendidikan "unknown" dan status pernikahan "married"
"""

df_maritalXeducation = df_train.groupby(['marital','education'])['job'].value_counts()
print(df_maritalXeducation["married"]["unknown"])
print()
print(df_maritalXeducation["divorced"]["unknown"])
print()
print(df_maritalXeducation["single"]["unknown"])
print()

"""Hasil menunjukkan:
1. Profesi terbanyak dari orang dengan status pendidikan "unknown" dan status pernikahan "married" adalah blue-collar
2. Profesi terbanyak dari orang dengan status pendidikan "unknown" dan status pernikahan "divorce" adalah blue-collar
3. Profesi terbanyak dari orang dengan status pendidikan "unknown" dan status pernikahan "single" adalah student

Ubah seluruh nilai "unknown" pada kolom job dengan ketentuan sbb:
1. Jika education = "primary", maka ubah "unknown" menjadi profesi terbanyak dari pelanggan yang berpendidikan "primary"
2. Jika education = "secondary", maka ubah "unknown" menjadi profesi terbanyak dari pelanggan yang berpendidikan "secondary"
3. Jika education = "tertiary", maka ubah "unknown" menjadi profesi terbanyak dari pelanggan yang berpendidikan "tertiary"
"""

def fillUnknownJob(df, reference_1, reference_2='job'):
    for val in df[reference_1].value_counts().index:
        if val != 'unknown':
            df.loc[(df[reference_1]==val) & (df[reference_2]=='unknown'),'job'] = df[df_train[reference_1]==val]['job'].value_counts().index[0]
    return df

df_train = fillUnknownJob(df_train,'education')
df_test = fillUnknownJob(df_test,'education')

"""Jika education = "unknown", maka cari profesi terbanyak berdasarkan pengelompokkan kolom marital"""

df_train = fillUnknownJob(df_train,'marital','education')
df_test = fillUnknownJob(df_test,'marital','education')

"""Kolom berikutnya yang mengandung nilai "unknown" adalah education.

Sama halnya dengan kasus sebelumnya (kolom job), tingkat pendidikan seseorang dapat dilihat dari profesi yang diambil. Namun pada beberapa kasus, seseorang mungkin saja tidak pernah menempuh pendidikan resmi namun memiliki profesi yang bahkan lebih baik dari mereka yang mengenyam pendidikan. Maka dari itu, pada kolom ini akan ditambahkan kategori baru yaitu "other" untuk merepresentasikan kasus tersebut
"""

df_train['education'].replace(to_replace='unknown', value='other', inplace=True)
df_test['education'].replace(to_replace='unknown', value='other', inplace=True)

"""Berikutnya adalah kolom contact yang merepresentasikan cara atau media yang digunakan oleh bank untuk menghubungi pelanggan. Pada deskripsi dataset disebutkan bahwa dataset ini berisi data campaign pemasaran jarak jauh melalui panggilan telepon sehingga tidak mungkin tercipta kategori baru selain "cellular" dan "telephone".

Namun, jumlah nilai "unknown" pada kolom contact sangat banyak sehingga sulit untuk mengimputasinya. Dengan demikian, kami akan tetap mempertahankan nilai "unknown" sebagai kategori dan hal ini juga berlaku pada kolom poutcome

EDA

Univariate
"""

for col in df_train.columns:
    if df_train[col].dtype != 'int64':
        count = df_train[col].value_counts()
        plt.figure(figsize = (8, 5))
        count.plot(kind = "bar")
        plt.title(f"Distribusi {col}")

"""Garfik di atas menunjukkan : 
1. mayoritas nasabah berprofesi blue-collar lalu diikuti oleh management dan technician
2. Lalu pada status pernikahan, didominasi oleh nasabah yang telah menikah
3. Status pendidikan terbanyak adalah secondary
4. Kebanyakan nasabah tidak memiliki masalah kredit
5. Jumlah nasabah yang memiliki pinjaman perumahan lebih banyak
6. Mayoritas nasabah tidak memiliki pinjaman personal 
7. Cellular merupakan cara yang paling sering digunakan oleh bank untuk menghubungi nasabah
8. Pihak bank sering menghubungi nasabah pada bulan mei
9. Keberhasilan masa campaign sebelumnya tidak bisa diukur dikarenakan kategori "unknown" yang sangat banyak. Namun jik kita membandingkan antara "success" dan "failure" maka akan didapati bahwa masa campaign sebelumnya lebih kerap gagal.
10. Kebanyakan nasabah adalah orang dewasa

Korelasi antar variabel
"""

plt.figure(figsize=(16,10))
sns.heatmap(df.corr(), annot=True)
plt.title("Correlation Heatmap",  fontsize = 15)
plt.show()

"""Dapat dilihat, terdapat beberapa kolom yang saling mempengaruhi, seperti kolom previous & pdays, kolom y & duration, kolom month & contact, kolom poutcome & contact dan kolom month & housing

Multivariate
"""

for col in df_train.columns:
    if col != 'y':
        plt.figure(figsize=(15,7))
        plt.title(col)
        df_train[df_train['y']==1][col].hist(alpha=1, color = 'red', label='y=1')
        df_train[df_train['y']==0][col].hist(alpha=0.3, color = 'blue', label='y=0')
        plt.legend()

"""1. Nasabah dengan profesi management merupakan nasabah yang melakukan deposito terbanyak dan nasabah dengan profesi blue-collar yang paling banyak tidak melakukan deposito.
2. Nasabah dengan balance yang lebih sedikit cenderung melakukan deposito bila dibandingkan dengan mereka yang memiliki balance yang lebih banyak namun mereka juga tertinggi dalam hal tidak melakukan deposito.
3. Jumlah nasabah yang melakukan deposito lebih banyak terjadi pada mereka yang tidak memiliki pinjaman perumahan bila dibandingkan dengan nasabah yang memiliki pinjaman perumahan. Hal tersebut juga terjadi pada kasus pinjaman personal, dimana nasabah yang tidak memiliki pinjaman personal lebih sering melakukan deposito
4. Nasabah yang dihubungi melalui 'cellular' lebih sering melakukan deposito
5. Terdapat tren pada kolom duration, jumlah nasabah yang melakukan deposito semakin menurun seiring dengan meningkatnya durasi komunikasi yang dilakukan oleh bank kepada nasabah.
6. Hal yang sama juga terjadi pada jumlah campaign yang dilakukan oleh bank kepada seorang nasabah. Dari hasil pengamatan didapatkan, bahwa semakin banyak jumlah campaign yang dilakukan oleh bank kepada seorang nasabah maka semakin menurun tingkat deposito
7. Jumlah nasabah yang melakukan deposito semakin menurun jika lama tidak dihubungi lagi oleh pihak bank. Dengan demikian, pihak bank perlu menentukan batas waktu paling lama untuk menghubungi kembali nasabah.
8. Nasabah cenderung melakukan deposito jika campaign sebelumnya berhasil 
9. Tingkat pendidikan tidak mempengaruhi tingkat deposito nasabah

Melihat trend antara balance dan job. Apakah semakin baik profesi seseorang akan mempengaruhi jumlah balance yang dimiliki?

Hasil menunjukkan, nasabah yang telah pensiun menghasilkan rata-rata balance yang paling tinggi
"""

df_train.groupby(['job'])['balance'].mean().plot(kind='bar');plt.show()

"""Melihat trend antara balance dan status pernikahan. Apakah status pernikahan nasabah mempengaruhi jumlah balance yang dimiliki?

Hasil menunjukkan, nasabah yang telah menikah memiliki rata-rata balance yang paling tinggi lalu disusul oleh mereka yang masih single dan terakhir adalah mereka yang telah berpisah
"""

df_train.groupby(['marital'])['balance'].mean().plot(kind='bar');plt.show()

"""Melihat sasaran campaign berdasarkan balance

Nasabah dengan balance yang kecil cenderung lebih sering dihubungi oleh pihak bank
"""

sns.jointplot(x='balance', y='campaign', data=df_train, color = 'blue', alpha=0.2);plt.show()

"""Campaign yang dilakukan pada saat ini paling sering dilakukan kepada nasabah baru dan mereka yang terakhir kali dihubungi pada 1 bulan yang lalu hingga 1 tahun yang lalu"""

sns.jointplot(x='pdays', y='campaign', data=df_train, color = 'green', alpha=0.2);plt.show()

"""Kami menemukan bahwa, campaign sebelumnya akan berhasil jika durasi komunikasi yang dilakukan oleh pihak bank kepada nasabah semakin lama"""

df_train.groupby('poutcome')['duration'].mean().plot(kind='bar');plt.show()

"""Data Preparation"""

dfFeature = pd.concat([df_train.iloc[:,df_train.columns!='y'],df_test.iloc[:,df_test.columns!='y']],ignore_index=True)
dfFeature = pd.get_dummies(dfFeature)

scaler = StandardScaler()
scaler.fit(dfFeature)

scalingFeature = scaler.transform(dfFeature)

X_train = scalingFeature[:len(df_train),:]
y_train = df_train.y

X_test = scalingFeature[len(df_train):,:]
y_test = df_test.y

print("Training : ",X_train.shape,y_train.shape)
print("Test : ",X_test.shape,y_test.shape)

X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state = 666, test_size= 0.20)

print("Training set : ",len(X_train))
print("Validation set : ",len(X_val))
print("Testing set : ",len(X_test))

"""Membuat model"""

model = keras.Sequential()
model.add(keras.layers.Dense(256, activation="relu", input_shape=(X_train.shape[-1],)))
model.add(keras.layers.Dropout(.2))
model.add(keras.layers.Dense(128, activation="relu", input_shape=(X_train.shape[-1],)))
model.add(keras.layers.Dropout(.1))
model.add(keras.layers.Dense(64, activation="relu"))
model.add(keras.layers.Dense(1, activation='sigmoid'))
model.compile(
    loss=keras.losses.BinaryCrossentropy(),
    optimizer=keras.optimizers.Adam(0.001),
    metrics=["accuracy"])
model.summary()

epochs = 200
batch = 128

reduce_lr = keras.callbacks.ReduceLROnPlateau(
    patience=10, min_lr=0.000001
)


history = model.fit(
    X_train, y_train,
    batch_size=batch,
    epochs=epochs,
    shuffle=True,
    verbose=1,
    validation_data=(X_val,y_val),
    callbacks=[reduce_lr]
)

## Melakukan visualisasi data
import matplotlib.pyplot as plt
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'bo', label= 'Training Accuracy')
plt.plot(epochs, val_acc, 'b', label= 'Validation Accuracy')
plt.title('Training and validation accuracy')

plt.figure()

plt.plot(epochs, loss, 'bo', label= "Training Loss")
plt.plot(epochs, val_loss, 'b', label= "Validation Loss")
plt.title('Training and validation loss')
plt.legend()

plt.show()

evaluation = pd.DataFrame({
    'loss':history.history['loss'],
    'val_loss':history.history['val_loss'],
    'accuracy':history.history['accuracy'],
    'val_accuracy':history.history['val_accuracy']
    })

columns = evaluation.keys()
N = int(len(columns)/2)

fig, axes = plt.subplots(1, N, sharex=True, figsize=(12,5))
fig.suptitle("Loss & Accuracy")

for i in range(N):
  column_name = evaluation.iloc[:,i*N:N*(i+1)].columns
  axes[i].set_title(f"{column_name[0]}")
  sns.lineplot(data=evaluation,x=range(len(evaluation)),y=evaluation[column_name[0]], ax=axes[i])
  sns.lineplot(data=evaluation,x=range(len(evaluation)),y=evaluation[column_name[1]], ax=axes[i])
  axes[i].legend(column_name)
  axes[i].set_xlabel("Epochs")
  axes[i].grid(False)
plt.show()

model.evaluate(X_test, y_test, verbose=1)

"""pred = model.predict(X_test)
pred[pred>=0.5] = 1
pred[pred<0.5] = 0
"""

### Setelah melakukan training the model, selanjutnya kami mencoba untuk memprediksi ke X_test (data baru)

## melakukan konversi probabilitas menjadi 0 or 1 untuk memprediksikan data kolom y
predictions = (model.predict(X_test) > 0.5).astype(int)

# summarize the first 5 cases
for i in range(50):
	print('%s => %d (expected %d)' % (X_test[i].tolist(), predictions[i], y_test[i]))

tf.keras.backend.clear_session()
from sklearn.metrics import confusion_matrix

conf_matrix = confusion_matrix(y_test, pred.squeeze())

conf_matrix

"""Perbandingan dengan metode lain

Logistic Regression
"""

from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
log_Regression=LogisticRegression(max_iter=3000)
log_Regression.fit(X_train,y_train)

y_pred = log_Regression.predict(X_test)

accuracy = accuracy_score(y_pred = y_pred, y_true = y_test)
print(f'Accuracy of the model Logistic Regression is {accuracy*100:.2f}%')

"""Random Forest"""

from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier()
rfc.fit(X_train, y_train)
rfcpredictions = rfc.predict(X_test)

accuracy = accuracy_score(y_pred = rfcpredictions, y_true = y_test)
print(f'Accuracy of the Random Forest Classifier model is {accuracy*100:.2f}%')

"""SVM"""

from sklearn.svm import SVC
svc = SVC()
svc.fit(X_train, y_train)
svcpredictions = svc.predict(X_test)
accuracy = accuracy_score(y_pred = svcpredictions, y_true = y_test)
print(f'Accuracy of the SVM model is {accuracy*100:.2f}%')

"""Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
dtc = DecisionTreeClassifier(random_state=0)
dtc.fit(X_train, y_train)
dtcprediction = dtc.predict(X_test)

accuracy = accuracy_score(y_pred = dtcprediction, y_true = y_test)
print(f'Accuracy of the Decision Tree Classifier model is {accuracy*100:.2f}%')